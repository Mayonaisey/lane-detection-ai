{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QxnzAO4JWyFX",
        "outputId": "8d45adb5-7263-4756-c0b8-591572340e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Train Annotations: 3626, Test Annotations: 2782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:32<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 1, Loss: 0.4382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:29<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 2, Loss: 0.2729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:29<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 3, Loss: 0.2180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:28<00:00,  6.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 4, Loss: 0.1966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:30<00:00,  6.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 5, Loss: 0.1824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:29<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 6, Loss: 0.1720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:28<00:00,  6.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 7, Loss: 0.1643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:29<00:00,  6.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 8, Loss: 0.1580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:28<00:00,  6.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 9, Loss: 0.1533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:27<00:00,  6.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Epoch 10, Loss: 0.1489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet - Accuracy: 0.9491, Precision: 0.4353, F1: 0.5873, IoU: 0.4158\n",
            "UNet - Confusion Matrix:\n",
            "[[21717914  1117410]\n",
            " [   92944   861300]]\n",
            "UNet model saved as 'UNet_lane_detection.pth'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.6516751..2.7311854].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.6606574..2.8823104].\n",
            "100%|██████████| 182/182 [00:18<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 1, Loss: 0.5435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 2, Loss: 0.4345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:17<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 3, Loss: 0.4210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:19<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 4, Loss: 0.4125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 5, Loss: 0.4068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 6, Loss: 0.3998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 7, Loss: 0.3960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:19<00:00,  9.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 8, Loss: 0.3924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 9, Loss: 0.3877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Epoch 10, Loss: 0.3859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSCNN - Accuracy: 0.9271, Precision: 0.2799, F1: 0.3637, IoU: 0.2223\n",
            "FastSCNN - Confusion Matrix:\n",
            "[[21561020  1274304]\n",
            " [  458825   495419]]\n",
            "FastSCNN model saved as 'FastSCNN_lane_detection.pth'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.6516751..2.7311854].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.6606574..2.8823104].\n",
            "100%|██████████| 182/182 [00:19<00:00,  9.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 1, Loss: 0.4679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 2, Loss: 0.4155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 3, Loss: 0.4020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 4, Loss: 0.3947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 5, Loss: 0.3885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 6, Loss: 0.3861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 7, Loss: 0.3822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 8, Loss: 0.3799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00,  9.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 9, Loss: 0.3775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:18<00:00, 10.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Epoch 10, Loss: 0.3748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENet - Accuracy: 0.8881, Precision: 0.2133, F1: 0.3231, IoU: 0.1927\n",
            "ENet - Confusion Matrix:\n",
            "[[20492226  2343098]\n",
            " [  318826   635418]]\n",
            "ENet model saved as 'ENet_lane_detection.pth'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.6516751..2.7311854].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.6606574..2.8823104].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, f1_score, jaccard_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import kagglehub\n",
        "dataset_path = kagglehub.dataset_download(\"manideep1108/tusimple\")\n",
        "dataset_path = os.path.join(dataset_path, 'TUSimple')\n",
        "train_set_path = os.path.join(dataset_path, 'train_set')\n",
        "test_set_path = os.path.join(dataset_path, 'test_set')\n",
        "test_json_path = os.path.join(test_set_path, 'test_tasks_0627.json')\n",
        "\n",
        "def load_annotations(json_paths, image_base_path):\n",
        "    annotations = []\n",
        "    for json_path in json_paths:\n",
        "        if not os.path.exists(json_path):\n",
        "            print(f\"[Warning] JSON file not found: {json_path}\")\n",
        "            continue\n",
        "        with open(json_path, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    data = json.loads(line)\n",
        "                    image_path = os.path.join(image_base_path, data['raw_file'])\n",
        "                    if os.path.exists(image_path):\n",
        "                        data['image_path'] = image_path\n",
        "                        annotations.append(data)\n",
        "                    else:\n",
        "                        print(f\"[Missing Image] {image_path}\")\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"[JSON Error] in {json_path}: {e}\")\n",
        "    return annotations\n",
        "\n",
        "train_json_files = ['label_data_0313.json', 'label_data_0531.json', 'label_data_0601.json']\n",
        "train_json_paths = [os.path.join(train_set_path, f) for f in train_json_files]\n",
        "train_annotations = load_annotations(train_json_paths, train_set_path)\n",
        "test_annotations = load_annotations([test_json_path], test_set_path)\n",
        "print(f\"[Info] Train Annotations: {len(train_annotations)}, Test Annotations: {len(test_annotations)}\")\n",
        "\n",
        "class LaneDataset(Dataset):\n",
        "    def __init__(self, annotations):\n",
        "        self.annotations = annotations\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ann = self.annotations[idx]\n",
        "        img = cv2.imread(ann['image_path'])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (256, 128)) / 255.0\n",
        "        img = (img - img.mean()) / img.std() #  normalization using z\n",
        "        img = torch.tensor(img, dtype=torch.float).permute(2, 0, 1)\n",
        "\n",
        "        mask = np.zeros((128, 256), dtype=np.uint8) #for semantic segmentation\n",
        "        for lane in ann['lanes']: #draw lane points(white) on mask(black bckgrnd)\n",
        "            for x, y in zip(lane, ann['h_samples']):\n",
        "                if x != -2:\n",
        "                    x = int(x * 256 / 1280)\n",
        "                    y = int(y * 128 / 720)\n",
        "                    if 0 <= x < 256 and 0 <= y < 128:\n",
        "                        cv2.circle(mask, (x, y), 2, 1, -1)\n",
        "        mask = torch.tensor(mask, dtype=torch.long)\n",
        "        return img, mask\n",
        "\n",
        "train_data, val_data = train_test_split(train_annotations, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(LaneDataset(train_data), batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(LaneDataset(val_data), batch_size=16, num_workers=2)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def conv_block(in_c, out_c):\n",
        "            return nn.Sequential(nn.Conv2d(in_c, out_c, 3, padding=1),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Conv2d(out_c, out_c, 3, padding=1),\n",
        "                                 nn.ReLU())\n",
        "        self.down1 = conv_block(3, 32)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.down2 = conv_block(32, 64)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.bridge = conv_block(64, 128)\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec2 = conv_block(128, 64)\n",
        "        self.up1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
        "        self.dec1 = conv_block(64, 32)\n",
        "        self.final = nn.Conv2d(32, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(self.pool1(d1))\n",
        "        b = self.bridge(self.pool2(d2))\n",
        "        u2 = self.dec2(torch.cat([self.up2(b), d2], dim=1))\n",
        "        u1 = self.dec1(torch.cat([self.up1(u2), d1], dim=1))\n",
        "        return self.final(u1)\n",
        "\n",
        "class FastSCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 2, kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "class ENet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(8, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.final = nn.ConvTranspose2d(32, 2, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = self.bottleneck(x)\n",
        "        x = self.final(x)\n",
        "        return x\n",
        "\n",
        "def train_and_evaluate(model, name):\n",
        "    model.to(device)\n",
        "    weights = torch.tensor([0.1, 1.0], device=device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    train_losses = []\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for imgs, masks in tqdm(train_loader):\n",
        "            imgs, masks = imgs.to(device), masks.to(device)\n",
        "            preds = model(imgs)\n",
        "            loss = criterion(preds, masks)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "        print(f\"{name} - Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            masks = masks.numpy()\n",
        "            outputs = model(imgs)\n",
        "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "            y_true.extend(masks.flatten())\n",
        "            y_pred.extend(preds.flatten())\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    iou = jaccard_score(y_true, y_pred, zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"{name} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, F1: {f1:.4f}, IoU: {iou:.4f}\")\n",
        "    print(f\"{name} - Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    plt.plot(train_losses, label=name)\n",
        "    plt.title(f\"Training Loss - {name}\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{name}_loss.png\")\n",
        "    plt.clf()\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{name}_lane_detection.pth\")\n",
        "    print(f\"{name} model saved as '{name}_lane_detection.pth'\")\n",
        "    return model\n",
        "\n",
        "models = {\n",
        "    \"UNet\": UNet(),\n",
        "    \"FastSCNN\": FastSCNN(),\n",
        "    \"ENet\": ENet()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    trained_model = train_and_evaluate(model, name)\n",
        "    trained_model.eval()\n",
        "    imgs, masks = next(iter(val_loader))\n",
        "    imgs = imgs.to(device)\n",
        "    with torch.no_grad():\n",
        "        preds = trained_model(imgs).argmax(dim=1).cpu().numpy()\n",
        "    imgs = imgs.cpu().permute(0, 2, 3, 1).numpy()\n",
        "    masks = masks.numpy()\n",
        "    for i in range(min(2, len(imgs))):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(\"Image\")\n",
        "        plt.imshow(imgs[i])\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(\"Ground Truth\")\n",
        "        plt.imshow(masks[i])\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(\"Prediction\")\n",
        "        plt.imshow(preds[i])\n",
        "        plt.axis('off')\n",
        "        plt.savefig(f\"{name}_visualization_{i}.png\")\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBv0Cw2rW2rs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}